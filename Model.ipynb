{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Load event mappings\n",
    "def load_event_mappings():\n",
    "    # Create mappings dictionary from your event_mappings.txt\n",
    "    website_events = {\n",
    "        0: 'nan', 2: '1', 3: '2', 4: '3', 5: '4', 6: '5', 7: '6', \n",
    "        8: '7', 9: '8', 10: '9', 11: '10', 12: '11', 13: '12', \n",
    "        14: '13', 15: '14', 16: '15', 17: '16', 18: '17', 19: '18', \n",
    "        20: '19', 21: '20', 22: '21', 23: '22', 24: '23'\n",
    "    }\n",
    "    \n",
    "    server_events = {\n",
    "        0: 'nan', 2: '1', 3: '2', 4: '3', 5: '4', 6: '5', 7: '6'\n",
    "    }\n",
    "    \n",
    "    return website_events, server_events\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Load and prepare data\n",
    "def prepare_data(csv_path):\n",
    "    # Read the CSV file\n",
    "    df = pd.read_csv(csv_path)\n",
    "    \n",
    "    # Convert clock to datetime\n",
    "    df['clock'] = pd.to_datetime(df['clock'])\n",
    "    \n",
    "    # Load event mappings\n",
    "    website_events, server_events = load_event_mappings()\n",
    "    \n",
    "    # Map the events to their names\n",
    "    df['website_event_name'] = df['website_events'].map(website_events)\n",
    "    df['server_event_name'] = df['server_events'].map(server_events)\n",
    "    \n",
    "    # Select features for prediction\n",
    "    feature_columns = [\n",
    "        'Download_Speed', 'Reach_Time', 'Time_to_First_Byte', 'HTTP_Probe_Duration',\n",
    "        'Page_Load_Time', 'DNS_Query_Time', 'Status_ID', 'Failed_step_of_scenario_WEB_HEALTH_CHECK',\n",
    "        'Interrupts_per_second', 'Load_average_15m_avg', 'Load_average_1m_avg',\n",
    "        'Load_average_5m_avg', 'CPU_utilization', 'CPU_idle_time', 'CPU_iowait_time',\n",
    "        'CPU_system_time', 'CPU_user_time', 'xvda_Disk_utilization',\n",
    "        'Boot_Space_Used_in_percent', 'Available_memory_in_percent', 'Memory_utilization',\n",
    "        'Space_Available', 'Boot_Space_Available', 'Available_memory', 'Total_memory'\n",
    "    ]\n",
    "    \n",
    "    # Prepare X (features)\n",
    "    X = df[feature_columns]\n",
    "    \n",
    "    # Prepare y (target) - we'll create two models, one for website events and one for server events\n",
    "    y_website = df['website_event_name']\n",
    "    y_server = df['server_event_name']\n",
    "    \n",
    "    # Encode the target variables\n",
    "    le_website = LabelEncoder()\n",
    "    le_server = LabelEncoder()\n",
    "    \n",
    "    y_website_encoded = le_website.fit_transform(y_website)\n",
    "    y_server_encoded = le_server.fit_transform(y_server)\n",
    "    \n",
    "    return X, y_website_encoded, y_server_encoded, le_website, le_server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Train models\n",
    "def train_models(X, y_website, y_server):\n",
    "    # Split the data\n",
    "    X_train, X_test, y_website_train, y_website_test, y_server_train, y_server_test = train_test_split(\n",
    "        X, y_website, y_server, test_size=0.2, random_state=42\n",
    "    )\n",
    "    \n",
    "    # Scale the features\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    \n",
    "    # Train website events model\n",
    "    website_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    website_model.fit(X_train_scaled, y_website_train)\n",
    "    \n",
    "    # Train server events model\n",
    "    server_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    server_model.fit(X_train_scaled, y_server_train)\n",
    "    \n",
    "    # Evaluate models\n",
    "    print(\"\\nWebsite Events Model Performance:\")\n",
    "    y_website_pred = website_model.predict(X_test_scaled)\n",
    "    print(classification_report(y_website_test, y_website_pred))\n",
    "    \n",
    "    print(\"\\nServer Events Model Performance:\")\n",
    "    y_server_pred = server_model.predict(X_test_scaled)\n",
    "    print(classification_report(y_server_test, y_server_pred))\n",
    "    \n",
    "    return website_model, server_model, scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the models...\n",
      "\n",
      "Website Events Model Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         1\n",
      "           1       0.00      0.00      0.00         3\n",
      "           2       0.00      0.00      0.00         0\n",
      "           3       0.25      0.01      0.01       142\n",
      "           4       0.00      0.00      0.00         3\n",
      "           5       0.00      0.00      0.00        69\n",
      "           6       0.00      0.00      0.00        20\n",
      "           7       0.13      0.07      0.09        45\n",
      "           8       0.00      0.00      0.00        11\n",
      "           9       0.00      0.00      0.00        18\n",
      "          10       0.00      0.00      0.00        21\n",
      "          11       0.00      0.00      0.00         1\n",
      "          12       0.00      0.00      0.00        37\n",
      "          13       0.46      0.49      0.48        87\n",
      "          14       0.00      0.00      0.00        15\n",
      "          17       0.00      0.00      0.00         0\n",
      "          18       0.00      0.00      0.00         2\n",
      "          19       0.00      0.00      0.00         1\n",
      "          20       0.00      0.00      0.00         2\n",
      "          21       0.00      0.00      0.00        31\n",
      "          22       0.92      0.99      0.95      3529\n",
      "          23       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.88      4039\n",
      "   macro avg       0.08      0.07      0.07      4039\n",
      "weighted avg       0.82      0.88      0.84      4039\n",
      "\n",
      "\n",
      "Server Events Model Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         2\n",
      "           1       1.00      0.60      0.75        10\n",
      "           3       0.00      0.00      0.00         1\n",
      "           4       0.00      0.00      0.00         1\n",
      "           5       1.00      1.00      1.00      4024\n",
      "           6       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           1.00      4039\n",
      "   macro avg       0.50      0.43      0.46      4039\n",
      "weighted avg       1.00      1.00      1.00      4039\n",
      "\n",
      "\n",
      "Models are ready for predictions!\n",
      "\n",
      "Predicted Website Event: nan\n",
      "Predicted Server Event: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\waqar.farooqui\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\waqar.farooqui\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\waqar.farooqui\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\waqar.farooqui\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\waqar.farooqui\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\waqar.farooqui\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\waqar.farooqui\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\waqar.farooqui\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\waqar.farooqui\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\waqar.farooqui\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# 4. Function to make predictions\n",
    "def predict_events(website_model, server_model, scaler, le_website, le_server, input_metrics):\n",
    "    # Scale the input metrics\n",
    "    input_scaled = scaler.transform([input_metrics])\n",
    "    \n",
    "    # Make predictions\n",
    "    website_pred = website_model.predict(input_scaled)\n",
    "    server_pred = server_model.predict(input_scaled)\n",
    "    \n",
    "    # Convert predictions back to event names\n",
    "    website_event = le_website.inverse_transform(website_pred)[0]\n",
    "    server_event = le_server.inverse_transform(server_pred)[0]\n",
    "    \n",
    "    return website_event, server_event\n",
    "\n",
    "# Main execution\n",
    "if __name__ == \"__main__\":\n",
    "    # Load and prepare data\n",
    "    X, y_website, y_server, le_website, le_server = prepare_data('Imputed_New-Dataset_Aiops_3.csv')\n",
    "    \n",
    "    # Train the models\n",
    "    print(\"Training the models...\")\n",
    "    website_model, server_model, scaler = train_models(X, y_website, y_server)\n",
    "    \n",
    "    # Example prediction\n",
    "    print(\"\\nModels are ready for predictions!\")\n",
    "    \n",
    "    # Example of how to use the models\n",
    "    sample_metrics = X.iloc[0].values  # Using first row as example\n",
    "    website_event, server_event = predict_events(\n",
    "        website_model, server_model, scaler, \n",
    "        le_website, le_server, sample_metrics\n",
    "    )\n",
    "    print(f\"\\nPredicted Website Event: {website_event}\")\n",
    "    print(f\"Predicted Server Event: {server_event}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing metrics...\n",
      "\n",
      "Predicted Events Based on Rules:\n",
      "Server Event: High CPU utilization (over 90% for 5m)\n",
      "Server Event: Load average is too high (per CPU load over 1.5 for 5m)\n",
      "Website Event: Page Load Time is High for 13.126.11.21 (More than 0.1 Seconds)\n",
      "Website Event: Page Load Time is High for 13.233.233.130 (More than 0.1 Seconds)\n",
      "Website Event: Page Load Time is High for 13.233.233.130 (More than 0.5 Seconds)\n",
      "Website Event: HTTP Probe Duration is High for 13.126.11.21 (More than 10 milliseconds)\n",
      "Website Event: HTTP Probe Duration is High for 13.233.233.130 (More than 10 milliseconds)\n",
      "Website Event: HTTP Probe Duration is High for 13.233.233.130 (More than 100 milliseconds)\n",
      "\n",
      "Detailed Metric Analysis:\n",
      "CPU Utilization: 94.818577% (Threshold: 90%)\n",
      "Download Speed: 1327.96562 Kbps (Thresholds: 1000, 500 Kbps)\n",
      "Reach Time: 0.0080042 seconds (Threshold: 0.5s)\n",
      "Page Load Time: 4.23 seconds (Thresholds: 0.1s, 0.5s)\n",
      "DNS Query Time: 24 ms (Thresholds: 40ms, 100ms)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Define event mappings\n",
    "def get_event_mappings():\n",
    "    server_events = {\n",
    "        0: 'nan',\n",
    "        1: 'Number of installed packages has been changed',\n",
    "        2: 'High CPU utilization (over 90% for 5m)',\n",
    "        3: 'Load average is too high (per CPU load over 1.5 for 5m)',\n",
    "        4: 'Zabbix agent is not available (for 3m)',\n",
    "        5: 'application-server has been restarted (uptime < 10m)',\n",
    "        6: '/etc/passwd has been changed'\n",
    "    }\n",
    "    \n",
    "    website_events = {\n",
    "        0: 'nan',\n",
    "        1: '65.2.33.65 is not available',\n",
    "        2: '3.110.32.172 is not available',\n",
    "        3: '52.66.107.192 is not available',\n",
    "        4: '13.126.209.90 is not available',\n",
    "        5: '65.2.168.33 is not available',\n",
    "        6: '13.127.178.245 is not available',\n",
    "        7: '13.126.11.21 is not available',\n",
    "        8: 'Reach Time is High for 13.126.11.21 (More than 0.5 Seconds)',\n",
    "        9: 'Download Speed is Low for 13.126.11.21',\n",
    "        10: 'Download Speed is Low for 13.126.11.21 (Less than 1000 Kbps)',\n",
    "        11: 'Page Load Time is High for 13.126.11.21 (More than 0.1 Seconds)',\n",
    "        12: 'HTTP Probe Duration is High for 13.126.11.21 (More than 10 milliseconds)',\n",
    "        13: 'DNS Query Time is High for 13.126.11.21 (More than 40 milliseconds)',\n",
    "        14: '13.233.233.130 is not available',\n",
    "        15: 'DNS Query Time is High for 13.233.233.130 (More than 40 milliseconds)',\n",
    "        16: 'Reach Time is High for 13.233.233.130 (More than 0.5 Seconds)',\n",
    "        17: 'Download Speed is Low for 13.233.233.130 (Less than 1000 Kbps)',\n",
    "        18: 'Page Load Time is High for 13.233.233.130 (More than 0.1 Seconds)',\n",
    "        19: 'HTTP Probe Duration is High for 13.233.233.130 (More than 10 milliseconds)',\n",
    "        20: 'DNS Query Time is High for 13.233.233.130 (More than 100 milliseconds)',\n",
    "        21: 'Download Speed is Low for 13.233.233.130 (Less than 500 Kbps)',\n",
    "        22: 'HTTP Probe Duration is High for 13.233.233.130 (More than 100 milliseconds)',\n",
    "        23: 'Page Load Time is High for 13.233.233.130 (More than 0.5 Seconds)'\n",
    "    }\n",
    "    \n",
    "    return server_events, website_events\n",
    "\n",
    "# Rule-based event detection\n",
    "def detect_events(metrics):\n",
    "    possible_events = []\n",
    "    \n",
    "    # Server Events Rules\n",
    "    if metrics['CPU_utilization'] > 90:\n",
    "        possible_events.append(('server', 2))\n",
    "    \n",
    "    if any(metrics[f'Load_average_{m}m_avg'] > 1.5 for m in [1, 5, 15]):\n",
    "        possible_events.append(('server', 3))\n",
    "    \n",
    "    # Website Events Rules\n",
    "    if metrics['Download_Speed'] < 1000:\n",
    "        possible_events.append(('website', 10))  # For 13.126.11.21\n",
    "        possible_events.append(('website', 17))  # For 13.233.233.130\n",
    "    \n",
    "    if metrics['Download_Speed'] < 500:\n",
    "        possible_events.append(('website', 21))  # For 13.233.233.130\n",
    "    \n",
    "    if metrics['Reach_Time'] > 0.5:\n",
    "        possible_events.append(('website', 8))   # For 13.126.11.21\n",
    "        possible_events.append(('website', 16))  # For 13.233.233.130\n",
    "    \n",
    "    if metrics['Page_Load_Time'] > 0.1:\n",
    "        possible_events.append(('website', 11))  # For 13.126.11.21\n",
    "        possible_events.append(('website', 18))  # For 13.233.233.130\n",
    "    \n",
    "    if metrics['Page_Load_Time'] > 0.5:\n",
    "        possible_events.append(('website', 23))  # For 13.233.233.130\n",
    "    \n",
    "    if metrics['HTTP_Probe_Duration'] > 0.01:  # 10 milliseconds\n",
    "        possible_events.append(('website', 12))  # For 13.126.11.21\n",
    "        possible_events.append(('website', 19))  # For 13.233.233.130\n",
    "    \n",
    "    if metrics['HTTP_Probe_Duration'] > 0.1:   # 100 milliseconds\n",
    "        possible_events.append(('website', 22))  # For 13.233.233.130\n",
    "    \n",
    "    if metrics['DNS_Query_Time'] > 40:\n",
    "        possible_events.append(('website', 13))  # For 13.126.11.21\n",
    "        possible_events.append(('website', 15))  # For 13.233.233.130\n",
    "    \n",
    "    if metrics['DNS_Query_Time'] > 100:\n",
    "        possible_events.append(('website', 20))  # For 13.233.233.130\n",
    "    \n",
    "    return possible_events\n",
    "\n",
    "# Function to predict events for given metrics\n",
    "def predict_events(metrics):\n",
    "    server_events, website_events = get_event_mappings()\n",
    "    possible_events = detect_events(metrics)\n",
    "    \n",
    "    print(\"\\nPredicted Events Based on Rules:\")\n",
    "    if not possible_events:\n",
    "        print(\"No events detected - all metrics are within normal ranges\")\n",
    "    else:\n",
    "        for event_type, event_id in possible_events:\n",
    "            if event_type == 'server':\n",
    "                print(f\"Server Event: {server_events[event_id]}\")\n",
    "            else:\n",
    "                print(f\"Website Event: {website_events[event_id]}\")\n",
    "    \n",
    "    return possible_events\n",
    "\n",
    "# Test with your provided metrics\n",
    "test_metrics = {\n",
    "    'Download_Speed': 1327.96562,\n",
    "    'Reach_Time': 0.0080042,\n",
    "    'Time_to_First_Byte': 0.0007837,\n",
    "    'HTTP_Probe_Duration': 5489.077,\n",
    "    'Page_Load_Time': 4.23,\n",
    "    'DNS_Query_Time': 24,\n",
    "    'Status_ID': 1,\n",
    "    'Failed_step_of_scenario_WEB_HEALTH_CHECK': 0,\n",
    "    'Interrupts_per_second': 313.5782956,\n",
    "    'Load_average_15m_avg': 23.539062,\n",
    "    'Load_average_1m_avg': 13.539062,\n",
    "    'Load_average_5m_avg': 13.5390620,\n",
    "    'CPU_utilization': 94.818577,\n",
    "    'CPU_idle_time': 63.181423,\n",
    "    'CPU_iowait_time': 10.016706,\n",
    "    'CPU_system_time': 17.233918,\n",
    "    'CPU_user_time': 73.517962,\n",
    "    'xvda_Disk_utilization': 160.04166729,\n",
    "    'Boot_Space_Used_in_percent': 46.13612725,\n",
    "    'Available_memory_in_percent': 41.499557,\n",
    "    'Memory_utilization': 58.500443,\n",
    "    'Space_Available': 9337511936,\n",
    "    'Boot_Space_Available': 719982592,\n",
    "    'Available_memory': 416624640,\n",
    "    'Total_memory': 1003925504\n",
    "}\n",
    "\n",
    "# Make predictions\n",
    "print(\"Analyzing metrics...\")\n",
    "predictions = predict_events(test_metrics)\n",
    "\n",
    "# Print detailed analysis\n",
    "print(\"\\nDetailed Metric Analysis:\")\n",
    "print(f\"CPU Utilization: {test_metrics['CPU_utilization']}% (Threshold: 90%)\")\n",
    "print(f\"Download Speed: {test_metrics['Download_Speed']} Kbps (Thresholds: 1000, 500 Kbps)\")\n",
    "print(f\"Reach Time: {test_metrics['Reach_Time']} seconds (Threshold: 0.5s)\")\n",
    "print(f\"Page Load Time: {test_metrics['Page_Load_Time']} seconds (Thresholds: 0.1s, 0.5s)\")\n",
    "print(f\"DNS Query Time: {test_metrics['DNS_Query_Time']} ms (Thresholds: 40ms, 100ms)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
