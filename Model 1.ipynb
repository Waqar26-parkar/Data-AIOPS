{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Load event mappings\n",
    "def load_event_mappings():\n",
    "    website_events = {\n",
    "        0: 'nan',\n",
    "        1: '65.2.33.65 is not available',\n",
    "        2: '3.110.32.172 is not available',\n",
    "        3: '52.66.107.192 is not available',\n",
    "        4: '13.126.209.90 is not available',\n",
    "        5: '65.2.168.33 is not available',\n",
    "        6: '13.127.178.245 is not available',\n",
    "        7: '13.126.11.21 is not available',\n",
    "        8: 'Reach Time is High for 13.126.11.21 (More than 0.5 Seconds)',\n",
    "        9: 'Download Speed is Low for 13.126.11.21',\n",
    "        10: 'Download Speed is Low for 13.126.11.21 (Less than 1000 Kbps)',\n",
    "        11: 'Page Load Time is High for 13.126.11.21 (More than 0.1 Seconds)',\n",
    "        12: 'HTTP Probe Duration is High for 13.126.11.21 (More than 10 milliseconds)',\n",
    "        13: 'DNS Query Time is High for 13.126.11.21 (More than 40 milliseconds)',\n",
    "        14: '13.233.233.130 is not available',\n",
    "        15: 'DNS Query Time is High for 13.233.233.130 (More than 40 milliseconds)',\n",
    "        16: 'Reach Time is High for 13.233.233.130 (More than 0.5 Seconds)',\n",
    "        17: 'Download Speed is Low for 13.233.233.130 (Less than 1000 Kbps)',\n",
    "        18: 'Page Load Time is High for 13.233.233.130 (More than 0.1 Seconds)',\n",
    "        19: 'HTTP Probe Duration is High for 13.233.233.130 (More than 10 milliseconds)',\n",
    "        20: 'DNS Query Time is High for 13.233.233.130 (More than 100 milliseconds)',\n",
    "        21: 'Download Speed is Low for 13.233.233.130 (Less than 500 Kbps)',\n",
    "        22: 'HTTP Probe Duration is High for 13.233.233.130 (More than 100 milliseconds)',\n",
    "        23: 'Page Load Time is High for 13.233.233.130 (More than 0.5 Seconds)'\n",
    "    }\n",
    "    \n",
    "    server_events = {\n",
    "        0: 'nan',\n",
    "        1: 'Number of installed packages has been changed',\n",
    "        2: 'High CPU utilization (over 90% for 5m)',\n",
    "        3: 'Load average is too high (per CPU load over 1.5 for 5m)',\n",
    "        4: 'Zabbix agent is not available (for 3m)',\n",
    "        5: 'application-server has been restarted (uptime < 10m)',\n",
    "        6: '/etc/passwd has been changed'\n",
    "    }\n",
    "    \n",
    "    return website_events, server_events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Load and prepare data\n",
    "def prepare_data(csv_path):\n",
    "    # Read the CSV file\n",
    "    df = pd.read_csv(csv_path)\n",
    "    \n",
    "    # Convert clock to datetime\n",
    "    df['clock'] = pd.to_datetime(df['clock'])\n",
    "    \n",
    "    # Load event mappings\n",
    "    website_events, server_events = load_event_mappings()\n",
    "    \n",
    "    # Map the events to their names\n",
    "    df['website_event_name'] = df['website_events'].map(website_events)\n",
    "    df['server_event_name'] = df['server_events'].map(server_events)\n",
    "    \n",
    "    # Select features for prediction\n",
    "    feature_columns = [\n",
    "        'Download_Speed', 'Reach_Time', 'Time_to_First_Byte', 'HTTP_Probe_Duration',\n",
    "        'Page_Load_Time', 'DNS_Query_Time', 'Status_ID', 'Failed_step_of_scenario_WEB_HEALTH_CHECK',\n",
    "        'Interrupts_per_second', 'Load_average_15m_avg', 'Load_average_1m_avg',\n",
    "        'Load_average_5m_avg', 'CPU_utilization', 'CPU_idle_time', 'CPU_iowait_time',\n",
    "        'CPU_system_time', 'CPU_user_time', 'xvda_Disk_utilization',\n",
    "        'Boot_Space_Used_in_percent', 'Available_memory_in_percent', 'Memory_utilization',\n",
    "        'Space_Available', 'Boot_Space_Available', 'Available_memory', 'Total_memory'\n",
    "    ]\n",
    "    \n",
    "    # Prepare X (features)\n",
    "    X = df[feature_columns]\n",
    "    \n",
    "    # Prepare y (target) - we'll create two models, one for website events and one for server events\n",
    "    y_website = df['website_event_name']\n",
    "    y_server = df['server_event_name']\n",
    "    \n",
    "    # Encode the target variables\n",
    "    le_website = LabelEncoder()\n",
    "    le_server = LabelEncoder()\n",
    "    \n",
    "    y_website_encoded = le_website.fit_transform(y_website)\n",
    "    y_server_encoded = le_server.fit_transform(y_server)\n",
    "    \n",
    "    return X, y_website_encoded, y_server_encoded, le_website, le_server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Train models\n",
    "def train_models(X, y_website, y_server):\n",
    "    # Split the data\n",
    "    X_train, X_test, y_website_train, y_website_test, y_server_train, y_server_test = train_test_split(\n",
    "        X, y_website, y_server, test_size=0.2, random_state=42\n",
    "    )\n",
    "    \n",
    "    # Scale the features\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    \n",
    "    # Train website events model\n",
    "    website_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    website_model.fit(X_train_scaled, y_website_train)\n",
    "    \n",
    "    # Train server events model\n",
    "    server_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    server_model.fit(X_train_scaled, y_server_train)\n",
    "    \n",
    "    # Evaluate models\n",
    "    print(\"\\nWebsite Events Model Performance:\")\n",
    "    y_website_pred = website_model.predict(X_test_scaled)\n",
    "    print(classification_report(y_website_test, y_website_pred))\n",
    "    \n",
    "    print(\"\\nServer Events Model Performance:\")\n",
    "    y_server_pred = server_model.predict(X_test_scaled)\n",
    "    print(classification_report(y_server_test, y_server_pred))\n",
    "    \n",
    "    return website_model, server_model, scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the models...\n",
      "\n",
      "Website Events Model Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00         0\n",
      "           3       0.00      0.00      0.00         3\n",
      "           4       0.00      0.00      0.00         1\n",
      "           5       0.00      0.00      0.00         1\n",
      "           7       0.00      0.00      0.00         1\n",
      "           8       0.25      0.01      0.01       142\n",
      "           9       0.00      0.00      0.00        21\n",
      "          10       0.00      0.00      0.00        69\n",
      "          11       0.00      0.00      0.00         2\n",
      "          12       0.00      0.00      0.00        31\n",
      "          13       0.13      0.07      0.09        45\n",
      "          14       0.00      0.00      0.00        37\n",
      "          15       0.00      0.00      0.00         0\n",
      "          16       0.00      0.00      0.00        18\n",
      "          17       0.46      0.49      0.48        87\n",
      "          18       0.00      0.00      0.00         3\n",
      "          19       0.00      0.00      0.00        11\n",
      "          20       0.00      0.00      0.00        15\n",
      "          21       0.00      0.00      0.00         1\n",
      "          22       0.00      0.00      0.00        20\n",
      "          23       0.92      0.99      0.95      3529\n",
      "\n",
      "    accuracy                           0.88      4039\n",
      "   macro avg       0.08      0.07      0.07      4039\n",
      "weighted avg       0.82      0.88      0.84      4039\n",
      "\n",
      "\n",
      "Server Events Model Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         1\n",
      "           1       1.00      1.00      1.00         2\n",
      "           2       1.00      0.60      0.75        10\n",
      "           3       0.00      0.00      0.00         1\n",
      "           5       0.00      0.00      0.00         1\n",
      "           6       1.00      1.00      1.00      4024\n",
      "\n",
      "    accuracy                           1.00      4039\n",
      "   macro avg       0.50      0.43      0.46      4039\n",
      "weighted avg       1.00      1.00      1.00      4039\n",
      "\n",
      "\n",
      "Models are ready for predictions!\n",
      "\n",
      "Predictions for test metrics:\n",
      "Predicted Website Event: DNS Query Time is High for 13.233.233.130 (More than 40 milliseconds)\n",
      "Predicted Server Event: application-server has been restarted (uptime < 10m)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\suyog.kulkarni\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\suyog.kulkarni\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\suyog.kulkarni\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\suyog.kulkarni\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\suyog.kulkarni\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\suyog.kulkarni\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\suyog.kulkarni\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\suyog.kulkarni\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\suyog.kulkarni\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\suyog.kulkarni\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# 4. Function to make predictions\n",
    "def predict_events(website_model, server_model, scaler, le_website, le_server, input_metrics):\n",
    "    # Scale the input metrics\n",
    "    input_scaled = scaler.transform([input_metrics])\n",
    "    \n",
    "    # Make predictions\n",
    "    website_pred = website_model.predict(input_scaled)\n",
    "    server_pred = server_model.predict(input_scaled)\n",
    "    \n",
    "    # Convert predictions back to event names\n",
    "    website_event = le_website.inverse_transform(website_pred)[0]\n",
    "    server_event = le_server.inverse_transform(server_pred)[0]\n",
    "    \n",
    "    return website_event, server_event\n",
    "\n",
    "# Main execution\n",
    "if __name__ == \"__main__\":\n",
    "    # Load and prepare data\n",
    "    X, y_website, y_server, le_website, le_server = prepare_data('C:/Users/suyog.kulkarni/OneDrive - Parkar Digital/Desktop/Unicorn/Imputed_New-Dataset_Aiops_3.csv')\n",
    "    \n",
    "    # Train the models\n",
    "    print(\"Training the models...\")\n",
    "    website_model, server_model, scaler = train_models(X, y_website, y_server)\n",
    "    \n",
    "    # Example prediction\n",
    "    print(\"\\nModels are ready for predictions!\")\n",
    "    \n",
    "    test_metrics = {\n",
    "        'Download_Speed': 1084.0767,\n",
    "        'Reach_Time': 0.00346,\n",
    "        'Time_to_First_Byte': 0.00342,\n",
    "        'HTTP_Probe_Duration': 1.066,\n",
    "        'Page_Load_Time': 0.003683,\n",
    "        'DNS_Query_Time': 110,\n",
    "        'Status_ID': 1,\n",
    "        'Failed_step_of_scenario_WEB_HEALTH_CHECK': 1,\n",
    "        'Interrupts_per_second': 308.4319097,\n",
    "        'Load_average_15m_avg': 0.193848,\n",
    "        'Load_average_1m_avg': 0.943848,\n",
    "        'Load_average_5m_avg': 0.504883,\n",
    "        'CPU_utilization': 1.3696452,\n",
    "        'CPU_idle_time': 98.6303548,\n",
    "        'CPU_iowait_time': 0.04182,\n",
    "        'CPU_system_time': 0.2341426,\n",
    "        'CPU_user_time': 0.9838802,\n",
    "        'xvda_Disk_utilization': 1.33915964,\n",
    "        'Boot_Space_Used_in_percent': 16.13612725,\n",
    "        'Available_memory_in_percent': 54.451467,\n",
    "        'Memory_utilization': 46.290275,\n",
    "        'Space_Available': 9388851200,\n",
    "        'Boot_Space_Available': 719982592,\n",
    "        'Available_memory': 546762752,\n",
    "        'Total_memory': 1003925504\n",
    "    }\n",
    "    \n",
    "    # Convert test_metrics to the correct format\n",
    "    test_df = pd.DataFrame([test_metrics])\n",
    "    test_metrics_array = test_df[X.columns].values[0]  # Ensure same column order as training data\n",
    "    \n",
    "    # Make predictions\n",
    "    website_event, server_event = predict_events(\n",
    "        website_model, server_model, scaler, \n",
    "        le_website, le_server, test_metrics_array\n",
    "    )\n",
    "    \n",
    "    print(\"\\nPredictions for test metrics:\")\n",
    "    print(f\"Predicted Website Event: {website_event}\")\n",
    "    print(f\"Predicted Server Event: {server_event}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
